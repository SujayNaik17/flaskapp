{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8c8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.io import wavfile\n",
    "# from scipy.signal import spectrogram\n",
    "\n",
    "# # Function to generate a spectrogram\n",
    "# def generate_spectrogram(audio_data, sample_rate):\n",
    "#     frequencies, times, Sxx = spectrogram(audio_data, sample_rate)\n",
    "#     return frequencies, times, Sxx\n",
    "\n",
    "# # Load and preprocess the audio file\n",
    "# def load_and_preprocess(file_path):\n",
    "#     sample_rate, audio_data = wavfile.read(file_path)\n",
    "#     if audio_data.ndim > 1:\n",
    "#         audio_data = np.mean(audio_data, axis=1)  # Convert to mono\n",
    "#     audio_data = audio_data / np.max(np.abs(audio_data))  # Normalize\n",
    "#     return sample_rate, audio_data\n",
    "\n",
    "# # Plot spectrograms side by side\n",
    "# def plot_spectrograms_side_by_side(file_paths):\n",
    "#     num_files = len(file_paths)\n",
    "#     fig, axs = plt.subplots(1, num_files, figsize=(15, 5), constrained_layout=True)\n",
    "\n",
    "#     for ax, (context, path) in zip(axs, file_paths.items()):\n",
    "#         sample_rate, audio_data = load_and_preprocess(path)\n",
    "#         frequencies, times, Sxx = generate_spectrogram(audio_data, sample_rate)\n",
    "        \n",
    "#         pcm = ax.pcolormesh(times, frequencies, 10 * np.log10(Sxx), shading='gouraud')\n",
    "#         ax.set_ylabel('Frequency [Hz]')\n",
    "#         ax.set_xlabel('Time [sec]')\n",
    "#         ax.set_title(f'{context} Bark')\n",
    "#         fig.colorbar(pcm, ax=ax, label='Intensity [dB]')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# # Example file paths (replace these with actual paths)\n",
    "# file_paths = {\n",
    "#     'Aggressive': 'agressive.wav',\n",
    "#      'Whining': 'whining.wav',\n",
    "#     'Pain': 'pain.wav',\n",
    "#     'Playful': 'happy.wav'\n",
    "   \n",
    "# }\n",
    "\n",
    "# # Plot spectrograms for different contexts side by side\n",
    "# plot_spectrograms_side_by_side(file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "484f5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.io import wavfile\n",
    "# from scipy.signal import spectrogram\n",
    "\n",
    "# # Function to generate a spectrogram\n",
    "# def generate_spectrogram(audio_data, sample_rate):\n",
    "#     frequencies, times, Sxx = spectrogram(audio_data, sample_rate)\n",
    "#     return frequencies, times, Sxx\n",
    "\n",
    "# # Load and preprocess the audio file\n",
    "# def load_and_preprocess(file_path):\n",
    "#     sample_rate, audio_data = wavfile.read(file_path)\n",
    "#     if audio_data.ndim > 1:\n",
    "#         audio_data = np.mean(audio_data, axis=1)  # Convert to mono\n",
    "#     audio_data = audio_data / np.max(np.abs(audio_data))  # Normalize\n",
    "#     return sample_rate, audio_data\n",
    "\n",
    "# # Plot spectrograms and amplitude side by side\n",
    "# def plot_spectrograms_and_amplitude(file_paths):\n",
    "#     num_files = len(file_paths)\n",
    "#     fig, axs = plt.subplots(2, num_files, figsize=(15, 10), constrained_layout=True)\n",
    "\n",
    "#     for i, (context, path) in enumerate(file_paths.items()):\n",
    "#         sample_rate, audio_data = load_and_preprocess(path)\n",
    "#         frequencies, times, Sxx = generate_spectrogram(audio_data, sample_rate)\n",
    "        \n",
    "#         # Plot spectrogram\n",
    "#         pcm = axs[0, i].pcolormesh(times, frequencies, 10 * np.log10(Sxx), shading='gouraud')\n",
    "#         axs[0, i].set_ylabel('Frequency [Hz]')\n",
    "#         axs[0, i].set_xlabel('Time [sec]')\n",
    "#         axs[0, i].set_title(f'{context} Bark Spectrogram')\n",
    "#         fig.colorbar(pcm, ax=axs[0, i], label='Intensity [dB]')\n",
    "        \n",
    "#         # Plot amplitude waveform\n",
    "#         time_axis = np.arange(audio_data.shape[0]) / sample_rate\n",
    "#         axs[1, i].plot(time_axis, audio_data)\n",
    "#         axs[1, i].set_ylabel('Amplitude')\n",
    "#         axs[1, i].set_xlabel('Time [sec]')\n",
    "#         axs[1, i].set_title(f'{context} Bark Amplitude')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# # Example file paths (replace these with actual paths)\n",
    "# file_paths = {\n",
    "#     'Aggressive': 'agressive.wav',\n",
    "#     'Whining': 'whining.wav',\n",
    "#     'Pain': 'pain.wav',\n",
    "#     'Playful': 'happy.wav'\n",
    "# }\n",
    "\n",
    "# # Plot spectrograms and amplitude for different contexts\n",
    "# plot_spectrograms_and_amplitude(file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee5b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.io import wavfile\n",
    "# from scipy.signal import spectrogram\n",
    "\n",
    "# # Function to generate a spectrogram\n",
    "# def generate_spectrogram(audio_data, sample_rate):\n",
    "#     frequencies, times, Sxx = spectrogram(audio_data, sample_rate)\n",
    "#     return frequencies, times, Sxx\n",
    "\n",
    "# # Function to calculate RMS intensity\n",
    "# def calculate_rms_intensity(audio_data, window_size):\n",
    "#     rms_intensity = np.sqrt(np.convolve(audio_data**2, np.ones(window_size)/window_size, mode='valid'))\n",
    "#     return rms_intensity\n",
    "\n",
    "# # Load and preprocess the audio file\n",
    "# def load_and_preprocess(file_path):\n",
    "#     sample_rate, audio_data = wavfile.read(file_path)\n",
    "#     if audio_data.ndim > 1:\n",
    "#         audio_data = np.mean(audio_data, axis=1)  # Convert to mono\n",
    "#     audio_data = audio_data / np.max(np.abs(audio_data))  # Normalize\n",
    "#     return sample_rate, audio_data\n",
    "\n",
    "# # Plot spectrograms, amplitude, frequency, and intensity\n",
    "# def plot_all_metrics(file_paths):\n",
    "#     num_files = len(file_paths)\n",
    "#     fig, axs = plt.subplots(4, num_files, figsize=(15, 20), constrained_layout=True)\n",
    "\n",
    "#     for i, (context, path) in enumerate(file_paths.items()):\n",
    "#         sample_rate, audio_data = load_and_preprocess(path)\n",
    "#         frequencies, times, Sxx = generate_spectrogram(audio_data, sample_rate)\n",
    "        \n",
    "#         # Calculate dominant frequency and RMS intensity\n",
    "#         dominant_frequency = frequencies[np.argmax(Sxx, axis=0)]\n",
    "#         rms_intensity = calculate_rms_intensity(audio_data, window_size=int(sample_rate * 0.05))  # 50 ms window\n",
    "        \n",
    "#         # Plot spectrogram\n",
    "#         pcm = axs[0, i].pcolormesh(times, frequencies, 10 * np.log10(Sxx), shading='gouraud')\n",
    "#         axs[0, i].set_ylabel('Frequency [Hz]')\n",
    "#         axs[0, i].set_xlabel('Time [sec]')\n",
    "#         axs[0, i].set_title(f'{context} Bark Spectrogram')\n",
    "#         fig.colorbar(pcm, ax=axs[0, i], label='Intensity [dB]')\n",
    "        \n",
    "#         # Plot amplitude waveform\n",
    "#         time_axis = np.arange(audio_data.shape[0]) / sample_rate\n",
    "#         axs[1, i].plot(time_axis, audio_data)\n",
    "#         axs[1, i].set_ylabel('Amplitude')\n",
    "#         axs[1, i].set_xlabel('Time [sec]')\n",
    "#         axs[1, i].set_title(f'{context} Bark Amplitude')\n",
    "\n",
    "#         # Plot dominant frequency\n",
    "#         axs[2, i].plot(times, dominant_frequency, color='green')\n",
    "#         axs[2, i].set_ylabel('Frequency [Hz]')\n",
    "#         axs[2, i].set_xlabel('Time [sec]')\n",
    "#         axs[2, i].set_title(f'{context} Dominant Frequency')\n",
    "\n",
    "#         # Plot RMS intensity\n",
    "#         rms_time_axis = np.arange(len(rms_intensity)) / sample_rate\n",
    "#         axs[3, i].plot(rms_time_axis, rms_intensity, color='red')\n",
    "#         axs[3, i].set_ylabel('RMS Intensity')\n",
    "#         axs[3, i].set_xlabel('Time [sec]')\n",
    "#         axs[3, i].set_title(f'{context} RMS Intensity')\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "# # Example file paths (replace these with actual paths)\n",
    "# file_paths = {\n",
    "#     'Aggressive': 'agressive.wav',\n",
    "#     'Whining': 'howling.wav',\n",
    "#     'Pain': 'pain_check.wav',\n",
    "# #     'Playful': 'happy.wav'\n",
    "# # \n",
    "\n",
    "# # Plot all metrics for different contexts\n",
    "# plot_all_metrics(file_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def41c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Define paths\n",
    "dataset_path = 'datasets'\n",
    "processed_path = 'processed_dataset'\n",
    "\n",
    "# Create processed dataset directory\n",
    "os.makedirs(processed_path, exist_ok=True)\n",
    "\n",
    "# Preprocess each file\n",
    "for category in os.listdir(dataset_path):\n",
    "    category_path = os.path.join(dataset_path, category)\n",
    "    processed_category_path = os.path.join(processed_path, category)\n",
    "    os.makedirs(processed_category_path, exist_ok=True)\n",
    "    \n",
    "    for file_name in os.listdir(category_path):\n",
    "        file_path = os.path.join(category_path, file_name)\n",
    "        y, sr = librosa.load(file_path, sr=22050, mono=True)  # Convert to mono, specific sample rate\n",
    "        y = librosa.util.normalize(y)  # Normalize\n",
    "        processed_file_path = os.path.join(processed_category_path, file_name)\n",
    "        sf.write(processed_file_path, y, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3e01d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=22050)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    return np.concatenate((np.mean(mfccs.T, axis=0), \n",
    "                           np.mean(chroma.T, axis=0),\n",
    "                           np.mean(spectral_contrast.T, axis=0)))\n",
    "\n",
    "# Example usage\n",
    "file_path = 'datasets/aggressive/aggressive.wav'\n",
    "features = extract_features(file_path)\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbfe897f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  aggressive       0.00      0.00      0.00       0.0\n",
      "       happy       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load features and labels\n",
    "def load_dataset(dataset_path):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for category in os.listdir(dataset_path):\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "        for file_name in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file_name)\n",
    "            feature = extract_features(file_path)\n",
    "            features.append(feature)\n",
    "            labels.append(category)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "dataset_path = 'processed_dataset'\n",
    "features, labels = load_dataset(dataset_path)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d085744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import librosa\n",
    "# import soundfile as sf\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report\n",
    "# import pickle\n",
    "\n",
    "# # Function to extract features from an audio file\n",
    "# def extract_features(file_path):\n",
    "#     y, sr = librosa.load(file_path, sr=22050)  # Load audio\n",
    "#     mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "#     chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "#     spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "#     return np.concatenate((np.mean(mfccs.T, axis=0), \n",
    "#                            np.mean(chroma.T, axis=0),\n",
    "#                            np.mean(spectral_contrast.T, axis=0)))\n",
    "\n",
    "# # Load dataset and extract features\n",
    "# def load_dataset(dataset_path):\n",
    "#     features = []\n",
    "#     labels = []\n",
    "#     for category in os.listdir(dataset_path):\n",
    "#         category_path = os.path.join(dataset_path, category)\n",
    "#         for file_name in os.listdir(category_path):\n",
    "#             file_path = os.path.join(category_path, file_name)\n",
    "#             feature = extract_features(file_path)\n",
    "#             features.append(feature)\n",
    "#             labels.append(category)\n",
    "#     return np.array(features), np.array(labels)\n",
    "\n",
    "# # Path to processed dataset\n",
    "# dataset_path = 'processed_dataset'\n",
    "# features, labels = load_dataset(dataset_path)\n",
    "\n",
    "# # Split data into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train a Random Forest Classifier\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Save the model to a file\n",
    "# with open('dog_bark_classifier.pkl', 'wb') as model_file:\n",
    "#     pickle.dump(clf, model_file)\n",
    "\n",
    "# # Evaluate the model\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Function to predict the type of bark from an audio file\n",
    "# def predict_bark_type(file_path, model):\n",
    "#     feature = extract_features(file_path).reshape(1, -1)\n",
    "#     prediction = model.predict(feature)\n",
    "#     return prediction[0]\n",
    "\n",
    "# # Load the trained model from file\n",
    "# with open('dog_bark_classifier.pkl', 'rb') as model_file:\n",
    "#     loaded_model = pickle.load(model_file)\n",
    "\n",
    "# # Example usage: Predicting the type of bark from a new audio file\n",
    "# new_audio_file = 'pain_check.wav'  # Replace with your new audio file path\n",
    "# predicted_bark_type = predict_bark_type(new_audio_file, loaded_model)\n",
    "# print(f'Predicted Bark Type: {predicted_bark_type}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48060a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import librosa\n",
    "# import soundfile as sf\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# import pickle\n",
    "\n",
    "# # Function to extract features from an audio file\n",
    "# def extract_features(file_path):\n",
    "#     y, sr = librosa.load(file_path, sr=22050)  # Load audio\n",
    "#     mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "#     chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "#     spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "#     return np.concatenate((np.mean(mfccs.T, axis=0), \n",
    "#                            np.mean(chroma.T, axis=0),\n",
    "#                            np.mean(spectral_contrast.T, axis=0)))\n",
    "\n",
    "# # Load dataset and extract features\n",
    "# def load_dataset(dataset_path):\n",
    "#     features = []\n",
    "#     labels = []\n",
    "#     for category in os.listdir(dataset_path):\n",
    "#         category_path = os.path.join(dataset_path, category)\n",
    "#         for file_name in os.listdir(category_path):\n",
    "#             file_path = os.path.join(category_path, file_name)\n",
    "#             feature = extract_features(file_path)\n",
    "#             features.append(feature)\n",
    "#             labels.append(category)\n",
    "#     return np.array(features), np.array(labels)\n",
    "\n",
    "# # Path to processed dataset\n",
    "# dataset_path = 'processed_dataset'\n",
    "# features, labels = load_dataset(dataset_path)\n",
    "\n",
    "# # Split data into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train a Random Forest Classifier\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Save the model to a file\n",
    "# with open('dog_bark_classifier.pkl', 'wb') as model_file:\n",
    "#     pickle.dump(clf, model_file)\n",
    "\n",
    "# # Evaluate the model\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Function to predict the type of bark from an audio file\n",
    "# def predict_bark_type(file_path, model):\n",
    "#     feature = extract_features(file_path).reshape(1, -1)\n",
    "#     prediction = model.predict(feature)\n",
    "#     return prediction[0]\n",
    "\n",
    "# # Load the trained model from file\n",
    "# with open('dog_bark_classifier.pkl', 'rb') as model_file:\n",
    "#     loaded_model = pickle.load(model_file)\n",
    "\n",
    "# # Example usage: Predicting the type of bark from a new audio file\n",
    "# new_audio_file = 'aggressive.wav'  # Replace with your new audio file path\n",
    "# predicted_bark_type = predict_bark_type(new_audio_file, loaded_model)\n",
    "# print(f'Predicted Bark Type: {predicted_bark_type}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14574fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'clf' is your trained RandomForestClassifier\n",
    "with open('dog_bark_classifier.pkl', 'wb') as model_file:\n",
    "    pickle.dump(clf, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd8f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the trained model\n",
    "with open('dog_bark_classifier.pkl', 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac21c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21184b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827efb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086a30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bc310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790dee78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ba598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a3d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143347cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'app'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    }
   ],
   "source": [
    "%run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3848b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6020d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !type requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3fd88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.2.1\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: http://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: c:\\users\\dell\\anaconda3\\lib\\site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: daal4py, imbalanced-learn, librosa, scikit-learn-intelex\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688546cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "librosa version: 0.10.2.post1\n",
      "numpy version: 1.23.5\n",
      "flask version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "# import librosa\n",
    "# import numpy as np\n",
    "# import flask\n",
    "\n",
    "# print(\"librosa version:\", librosa.__version__)\n",
    "# print(\"numpy version:\", np.__version__)\n",
    "# print(\"flask version:\", flask.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212e922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
